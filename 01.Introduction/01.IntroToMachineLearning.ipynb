{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {},
   "source": [
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "649f1ecd-96f5-429f-a0ba-475e955ff6f7",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9765ba7b-e0ab-48c8-b28f-ed9bd129cab1",
   "metadata": {},
   "source": [
    "## 01. Intorduction to Machine Learning\n",
    "\n",
    "### Live Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c1220f2-494c-4e8d-9bb6-26ff4395dd76",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/diabetic_data.csv', na_values=['?'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78a932bf-082b-4b3c-8ece-e25c9cfbad8d",
   "metadata": {},
   "source": [
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f578bdb7-c737-4abe-84ad-4782b539f67c",
   "metadata": {},
   "source": [
    "We want to make a model that checks bss readmitted feature which treatment is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "834d8a53-76b9-48b0-8371-9b1fbe08b3ac",
   "metadata": {},
   "source": [
    "df.readmitted.unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83cddfc9-855f-41e5-b715-2060b32d366b",
   "metadata": {},
   "source": [
    "df.readmitted.value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1a46c2bd-3484-4136-9224-79acea0a1f19",
   "metadata": {},
   "source": [
    "We see that NOT readmitted is largest, above 30 days is second, below < 30 less.\n",
    "If we want we can combine >30 and < 30 with YES / NO classification.\n",
    "The variable is categorical and is target, we need **classification** algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec05f9b7-dc53-4493-8e08-a845b3a33ef8",
   "metadata": {},
   "source": [
    "df.race.value_counts(dropna=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fe66d73-679c-4004-839b-c5be99d35dd9",
   "metadata": {},
   "source": [
    "df.gender.value_counts(dropna=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80b72234-5a68-43f4-a712-73f9574f2bb6",
   "metadata": {},
   "source": [
    "df.age.value_counts(dropna=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8d34ecd-4fbe-485e-973f-8fa8ddbdf3dd",
   "metadata": {},
   "source": [
    "# normalizing the data in %\n",
    "df.age.value_counts(dropna=False) / len(df) * 100"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b7da3f53-f0e7-4c2a-9367-4e694652152f",
   "metadata": {},
   "source": [
    "As we have BIAS in the data, the age above 50 has a lot of records, therefore, the model will not be accurate for young people. The model will be *tuned* for the **biggest** count of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c7a3267-0c31-4c14-83b3-4377dbe4cd39",
   "metadata": {},
   "source": [
    "df.discharge_disposition_id.value_counts(dropna=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "56688322-9933-4116-a360-57a7dd058347",
   "metadata": {},
   "source": [
    "This variable is considered HIGH CARDINALITY - the categorial variable has many values. The level of the category is the count of the unique values in it. This is **HIGH LEVEL CAT**.\n",
    "We can:\n",
    "1. Do nothing,\n",
    "2. Unite on certain bassis\n",
    "3. Can be dropped from DS with **COUTION**. For the demo will be dropped in order to be able to create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76ea7e80-e73f-4764-b852-3258e7b59c78",
   "metadata": {},
   "source": [
    "df.metformin.value_counts(dropna=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e764d9-3b2c-4aba-9ebd-eef0715bf5ba",
   "metadata": {},
   "source": [
    "Above is categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85d597c3-49a3-4239-a797-7b6c93178eaf",
   "metadata": {},
   "source": [
    "df.patient_nbr"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "74ee572a-ff47-41f8-aacd-62d60f768d5a",
   "metadata": {},
   "source": [
    "It is type int, however, we cannot perform matematical operations on the ID, so it is considered 'categorical'. The variable has **TOO BIG ENTROPY**, brings less information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd315cee-9581-45dd-b940-cb9cdfdb3cee",
   "metadata": {},
   "source": [
    "df.patient_nbr.nunique() / len(df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f9ff014-b8ef-4d49-b74d-0edbb9e70b20",
   "metadata": {},
   "source": [
    "df.patient_nbr.value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57835cb5-68e5-4d91-8839-4dbcdf39a2e4",
   "metadata": {},
   "source": [
    "df[df.patient_nbr == 88785891]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "38b0e448-995f-44fc-bd83-38bbda614d13",
   "metadata": {},
   "source": [
    "Separating the **target**. Remaining will be called **attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef5a5d12-0a46-4ffe-b086-2e4b07768db2",
   "metadata": {},
   "source": [
    "attr = df.drop(columns='readmitted')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad20f154-3e6c-42b3-bdcd-1bab7800324d",
   "metadata": {},
   "source": [
    "trgt = df['readmitted']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f54905ec-74c9-49fa-ad6e-509f70705eca",
   "metadata": {},
   "source": [
    "trgt"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "79e5c7c2-dbff-4905-83a2-e706d602ec9f",
   "metadata": {},
   "source": [
    "We drop varibales (columns) from the **attr** and **WRITE DOWN WHY ARE WE DOING THAT!!!** In our case, the 'encounter_id' & 'patient_nbr' are considered categorical variables with high entropy and no value for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5dc6b218-426d-4611-b575-3b2cbfb3aa41",
   "metadata": {},
   "source": [
    "attr = attr.drop(columns=['encounter_id', 'patient_nbr'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18aa7898-f405-4660-9928-d8869b435447",
   "metadata": {},
   "source": [
    "attr.diag_1.value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5fe8d6c3-257f-4b3d-bae3-ed49370edade",
   "metadata": {},
   "source": [
    "As per the DS description, we have more than 800 distinct values, **HIGH ENTROPY** -> useless. We have NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b7a4691-925d-4b86-b46d-a0617f3d1815",
   "metadata": {},
   "source": [
    "len(attr[attr.diag_3.isna()])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8b44262f-05c2-4489-9e88-da5affba5aab",
   "metadata": {},
   "source": [
    "We can remove them, however if we drop them, all attr df will have 0 observations. So we can remove NaN id different cols only. The *WEIGHT* col will be dropped due to too many missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "382ab275-a7f3-4d61-95d4-6354d35573a2",
   "metadata": {},
   "source": [
    "attr.weight.isna().count()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "975649af-e19f-4712-a106-d79e64b4b51c",
   "metadata": {},
   "source": [
    "attr = attr.drop(columns='weight')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0ab232d9-dc54-4e9d-8b8e-91a6044a6f8c",
   "metadata": {},
   "source": [
    "Removing further more usless columns with too many NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267cab20-6194-4821-9b13-418c9cf2ffe3",
   "metadata": {},
   "source": [
    "attr = attr.drop(columns=['payer_code', 'medical_specialty'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f42b3b58-0b9f-43d7-98a5-24630dbcf723",
   "metadata": {},
   "source": [
    "We now check the numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fe279149-05f5-4805-894c-9c620c43e7b1",
   "metadata": {},
   "source": [
    "df.time_in_hospital.hist(bins='fd')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "afd47d93-39cc-48b1-b175-78d2cda63900",
   "metadata": {},
   "source": [
    "df.num_medications.hist(bins='fd')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d7eeee20-fb76-4af2-8557-035e84a82df6",
   "metadata": {},
   "source": [
    "Some patients are taking more than 50 medicaments!! Useless depending of what we want to achieve. There is problem with this huge range from 0 to 80. And normally is a lot more, times times more. The problem arises when we save a number into the RAM, the number is not saved exact and we obtain numerical errors from basiccomputer math operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d7121093-296d-49d7-9bcc-1c76eadbacbb",
   "metadata": {},
   "source": [
    "0.1 + 0.2"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9542fc4b-84ad-4574-b039-7334e865977d",
   "metadata": {},
   "source": [
    "We have error from rounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "01541e2b-f433-49c7-a200-50f157b72c50",
   "metadata": {},
   "source": [
    "10000000000000000.0 + 1 == 10000000000000000.0"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0df8f882-5430-4200-ae10-198e4de7ea72",
   "metadata": {},
   "source": [
    "the errorrs are less if the numbers we are working with are in range [-1: 1]. So we must pass numbers to the model close to 0. Therefore we are scaling the data using Z-score or other methods. Below is Z-Score example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f5065772-febd-484e-bd80-3902ffe56c2a",
   "metadata": {},
   "source": [
    "zscore = (df.num_medications - df.num_medications.mean()) / df.num_medications.std()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "89a4aac9-4df0-41e1-839f-c32d4b78a279",
   "metadata": {},
   "source": [
    "zscore.hist(bins='fd')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c30fa059-3a7c-4481-b1c8-9e142ab78b3a",
   "metadata": {},
   "source": [
    "Below min-max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6e2dd5d0-ef2c-48ac-a97e-04a1729f95ea",
   "metadata": {},
   "source": [
    "min_max = (df.num_medications - df.num_medications.min()) / (df.num_medications.max() - df.num_medications.min())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b775b8fc-40eb-4e78-b537-468886d7d89d",
   "metadata": {},
   "source": [
    "min_max.hist(bins='fd')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5ca0fe0c-ccd5-47b5-8cef-7e1d10e3ab63",
   "metadata": {},
   "source": [
    "Category vars -> must be passed as numbers to the model. We cannot pass a string to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0c4c9062-5a8f-4152-8c19-9b58752be417",
   "metadata": {},
   "source": [
    "df.metformin"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ee1f7743-1ae1-4abc-be96-c9aae4a59a41",
   "metadata": {},
   "source": [
    "# similar to melt\n",
    "pd.get_dummies(df.metformin).astype(int)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "99730a73-8df5-4960-8822-bad61919cb6b",
   "metadata": {},
   "source": [
    "# change in column names\n",
    "pd.get_dummies(df[['metformin']]).astype(int)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "680bc3d2-6d8c-479e-9ce1-166c5bee6e6d",
   "metadata": {},
   "source": [
    "We need to encode the values with different encoding. Like **one-hot** or **multy** encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6b8a625f-da41-4dd5-8562-9aec46853219",
   "metadata": {},
   "source": [
    "attr.metformin.replace({'No':-99, 'Down': -1, 'Steady': 0, 'Up': 1})"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8fe7944e-47ed-45ef-a7b7-bd26bf0c0a00",
   "metadata": {},
   "source": [
    "Now it is in numbers. We must pass all categorical vars in the encoding process. The model will work with the numbers without knowing that these are categories. In order not to confuse the model, we must encode using **get_dummies** and spread to more columns the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7f853671-0a48-4822-a5cc-fdadcfbad912",
   "metadata": {},
   "source": [
    "pd.get_dummies(attr)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0da5e715-f781-4dfd-b44b-3e89df0d5850",
   "metadata": {},
   "source": [
    "The column number is increased, however the model can work with that! We can also reduce the cols using **drop_first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5b7a2d42-0cb2-4ebc-af7b-0a070396fc57",
   "metadata": {},
   "source": [
    "attr = pd.get_dummies(attr, drop_first=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "983632d1-de54-4d10-9ce9-876d77119dee",
   "metadata": {},
   "source": [
    "Now we need to scale the values (normalize). Importing minmax scaler, fit to the current attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "914e4523-9573-4741-a912-2b501f3504dd",
   "metadata": {},
   "source": [
    "MinMaxScaler()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "45c6a47d-e2b9-4e9b-b6ae-e37e99683af7",
   "metadata": {},
   "source": [
    "scaler = MinMaxScaler()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f89658a-7ce6-4e3d-99b8-d3dcd7448a11",
   "metadata": {},
   "source": [
    "scaler.fit(attr)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fdc6ac64-f1f5-4e82-ae78-dbe50067a99c",
   "metadata": {},
   "source": [
    "# original value range\n",
    "scaler.data_range_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b846d7f9-310e-462d-8d72-644e34b16d80",
   "metadata": {},
   "source": [
    "# transform scale / normalize where the max is 1 and min is 0\n",
    "attr = scaler.transform(attr)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "101c498f-d75b-49b7-beee-28140e2139c6",
   "metadata": {},
   "source": [
    "attr.max(axis=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f85914a1-f905-4de3-be5c-8fcd964a4450",
   "metadata": {},
   "source": [
    "attr.min(axis=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "03899bf2-e960-4bce-887f-6168aa960b90",
   "metadata": {},
   "source": [
    "The output is numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "702fc060-3abb-4b5b-9eb0-24ef903cf892",
   "metadata": {},
   "source": [
    "# same as original df\n",
    "attr.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fee7b0ec-73b1-4aec-bc07-e45904dcf7bc",
   "metadata": {},
   "source": [
    "# everything is a floa\n",
    "attr.dtype"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e8ffa2c6-7e11-45cd-8c25-35135b3316d9",
   "metadata": {},
   "source": [
    "The other option is OneHotEncoder, LabelEncoder. The LabelEncoder is **REPLACE** function. These operations are **ONLY FOR THE ATTRIBUTES, NOT FOR THE TARGET**. For SKLEARN model, must have 2D array, sorted values, row - observation, column - feature. We use LogisticRegression. We are passing the attributes as array and target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ce622d3d-ee21-4a50-a40e-a0920e1886ba",
   "metadata": {},
   "source": [
    "model = LogisticRegression()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3c3dd008-3597-4195-a621-c94d9dff99d8",
   "metadata": {},
   "source": [
    "model.fit(attr, trgt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd1b8d5-cdc9-44a7-adba-ad0ea7d1040e",
   "metadata": {},
   "source": [
    "The ML is to **PASS CORRECT DATA** and **EVALUATE THE MODEL**. It seems that the fitting was not completed with success. However:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "151e3f0a-be36-43ed-a040-f2d4cb334309",
   "metadata": {},
   "source": [
    "model.score(attr, trgt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c852762a-ee8b-4d37-a8a5-e414ac319287",
   "metadata": {},
   "source": [
    "The score is **classification accuracy**. We need to evaluate if the score is OK for us. Otherwise we can make feature engineering, feature selections etc to increase the score, finetune it etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851d60b-97ed-41d2-8312-4cf10d0b6c3b",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
