{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T23:55:47.025797Z",
     "start_time": "2024-09-20T23:55:39.561759Z"
    }
   },
   "source": [
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed2abf96a017cba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T23:55:58.368339Z",
     "start_time": "2024-09-20T23:55:48.926033Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4e9a4fbaf9fa7c41",
   "metadata": {},
   "source": [
    "# Creating Linear Regression Model\n",
    "\n",
    "## Simple Linear Regression\n",
    "The simpler linear regression is suitable for one input feature. The model is represented by the equation of a strait line. \n",
    "\n",
    "### Workflow\n",
    "1. Generate training data by providing initial parameters a & b\n",
    "2. Add noise to the training data\n",
    "3. Define **linear regression algorithm**\n",
    "4. Define **loss function**\n",
    "5. Iterate over the training data to find parameters\n",
    "6. Generate test data\n",
    "7. Score the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28b2794-fe7a-4974-bc1e-b71005a64918",
   "metadata": {},
   "source": [
    "# defining parameters of the regression. These are initial parameters ONLY for generating data and comparing \n",
    "# calculated parameters\n",
    "a_init = 4\n",
    "b_init = 1\n",
    "# generating training input data\n",
    "x = np.linspace(0, 10, 1000)\n",
    "y = a_init * x + b_init"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "014ca8e0-3ca5-4b0d-a5f9-ed308bfea2bf",
   "metadata": {},
   "source": [
    "# plotting the line equation of the data\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2790109-80bc-4370-bf4e-4765a7a3c2db",
   "metadata": {},
   "source": [
    "# addinig noise to the output data\n",
    "eps = np.random.randn(len(x))\n",
    "y_noise = y + eps"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf2980c-051d-4819-9944-646f647220ca",
   "metadata": {},
   "source": [
    "# plotting the line and the noised data\n",
    "plt.plot(x, y, label='Input/Output data w/out noise')\n",
    "plt.scatter(x, y_noise, c='r', s=0.2, label='Input/Output data with noise')\n",
    "plt.xlabel('Input data')\n",
    "plt.ylabel('Output data')\n",
    "plt.title('Real data and equation describing it without the noise')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ca61579d-e060-4422-8c53-854dcd5794ce",
   "metadata": {},
   "source": [
    "What is clear on the plot is that the parameters $a = 4$ and $b = 1$, which were used to model the equation of the data, describe the noised data as best possible. Assuming we **ONLY** have $x$ and $y_noise$ and the parameters $a$ and $b$ are **unknown**, we will now create a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc0e0e-c003-40d3-bce3-43d9b2688863",
   "metadata": {},
   "source": [
    "Defining the MSE:\n",
    "$$J = \\frac{1}{n}\\sum_{i=1}^n(y_i-(ax_i+b))^2$$\n",
    "\n",
    "This in python:\n",
    "```python\n",
    "def mean_squared_error(x, y, a, b):\n",
    "    \"\"\"\n",
    "    The function calculates mean squared error\n",
    "    \n",
    "    :param x: float: original input data\n",
    "    :param y: float: original output data with noise/variance included\n",
    "    :param a: float: target parameter 'a'\n",
    "    :param b: float: interceptor 'b'\n",
    "    :return: mean squared error\n",
    "    \"\"\"\n",
    "\n",
    "    return 1 / len(x) * np.sum(y - (a * x + b)) ** 2   \n",
    "```\n",
    "\n",
    "From that formula we get the gradient for the parameters:\n",
    "$$\\frac {\\partial J}{\\partial a} = -\\frac{2}{n}\\sum_{i=1}^nx_i(y_i - \\tilde{y_i})$$\n",
    "$$\\frac {\\partial J}{\\partial b} = -\\frac{2}{n}\\sum_{i=1}^n(y_i - \\tilde{y_i})$$\n",
    "\n",
    "```python\n",
    "a_gradient = -2 / len(x) * np.sum(x * (y - (a * x + b)))\n",
    "b_gradient = -2 / len(x) * np.sum(y - (a * x + b))\n",
    "```\n",
    "\n",
    "Finally, calculating the gradient descent is iterative operation. The result from each iteration is passed again to the next iteration of the calculation:\n",
    "$$\\theta_{new} = \\theta_{old} - \\alpha \\cdot \\nabla L(\\theta)$$\n",
    "```python\n",
    "def gradient_descent(x, y, a, b, learning_rate):\n",
    "    a_grad, b_grad = parameter_gradient(x, y, a, b)\n",
    "\n",
    "    a_new = a - learning_rate * a_grad\n",
    "    b_new = b - learning_rate * b_grad\n",
    "\n",
    "    return a_new, b_new   \n",
    "```\n",
    "We set the starting value of the parameters, pass the learning rate and we calculate the final parameters.\n",
    "```python\n",
    "a = 80\n",
    "b = 12\n",
    "learning_rate = 0.02\n",
    "for i in range(600):\n",
    "    a, b = gradient_descent(x, y_noise, a , b, learning_rate)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14524e59-5198-4e56-bc43-9b124289608f",
   "metadata": {},
   "source": [
    "def parameter_gradient(x, y, a, b):\n",
    "    \"\"\" using MSE \"\"\"\n",
    "\n",
    "    a_gradient = -2 / len(x) * np.sum(x * (y - (a * x + b)))\n",
    "    b_gradient = -2 / len(x) * np.sum(y - (a * x + b))\n",
    "\n",
    "    return a_gradient, b_gradient"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea51f29-e41d-4080-b798-cb54b0c625e9",
   "metadata": {},
   "source": [
    "def gradient_descent(x, y, a, b, learning_rate):\n",
    "    a_grad, b_grad = parameter_gradient(x, y, a, b)\n",
    "\n",
    "    a_new = a - learning_rate * a_grad\n",
    "    b_new = b - learning_rate * b_grad\n",
    "\n",
    "    return a_new, b_new"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d9c8f0-c9a1-4ed1-b389-cf0ecf1e628f",
   "metadata": {},
   "source": [
    "a = 80\n",
    "b = 12\n",
    "learning_rate = 0.02\n",
    "for i in range(600):\n",
    "    a, b = gradient_descent(x, y_noise, a, b, learning_rate)\n",
    "\n",
    "coef = (a, b)\n",
    "\n",
    "y_pred = a * x + b\n",
    "\n",
    "plt.plot(x, y_pred, label='Predicted output')\n",
    "plt.scatter(x, y_noise, c='r', s=1, label='Real output')\n",
    "plt.xlabel('Input data')\n",
    "plt.ylabel('Output data')\n",
    "plt.title('Model against the training data')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f929c290-b352-4a06-83b1-7906d003fb07",
   "metadata": {},
   "source": [
    "We can see that the model describes the data very accurate. We now generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05581dc2-310c-4770-9268-8be943cc0159",
   "metadata": {},
   "source": [
    "# Generate test data (new x values)\n",
    "x_test = np.linspace(10, 15, 500)  # New range for test data\n",
    "\n",
    "# Generate corresponding y values based on the same linear relationship (without noise)\n",
    "y_test = a_init * x_test + b_init\n",
    "# add noise\n",
    "eps_test = np.random.randn(len(x_test))\n",
    "y_test_noise = y_test + eps_test"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb1e6f27-7fbd-4d6e-8bbc-2336c00d056c",
   "metadata": {},
   "source": [
    "# test the model on the test data with the calculated coef\n",
    "a, b = coef\n",
    "y_test_pred = a * x_test + b\n",
    "\n",
    "plt.plot(x_test, y_test_pred, label='Predicted output')\n",
    "plt.scatter(x_test, y_test_noise, c='r', s=1, label='Real output')\n",
    "plt.xlabel('Input data')\n",
    "plt.ylabel('Output data')\n",
    "plt.title('Model against test data')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c369f052-35ba-4089-a630-66a6f585c31a",
   "metadata": {},
   "source": [
    "In order to score the model, we will implement $R^2$ score.\n",
    "\n",
    "The $R^2$ score, also known as the **coefficient of determination**, is a statistical measure that evaluates how well a regression model fits the data. It is commonly used to assess the performance of [[linear regression]] models and provides insight into how much of the variance in the dependent variable ( $y$ ) is explained by the independent variable(s) ( $x$ ).\n",
    "\n",
    "### Formula for $R^2$:\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}$$\n",
    "Where:\n",
    "\n",
    "- $y_i$​: The actual value of the dependent variable.\n",
    "- $\\hat{y}_i$​: The predicted value from the model.\n",
    "- $\\bar{y}$​: The mean of the actual values.\n",
    "- The numerator $\\sum (y_i - \\hat{y}_i)^2$ represents the **Residual Sum of Squares (RSS)**, which is the total error or difference between actual and predicted values.\n",
    "- The denominator $\\sum (y_i - \\bar{y})^2$ represents the **Total Sum of Squares (TSS)**, which is the total variance of the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2052a68a-c98c-4620-b620-91f0a3d893cd",
   "metadata": {},
   "source": [
    "def r_2_score(y_real, y_pred):\n",
    "    return 1 - np.sum((y_real - y_pred) ** 2) / np.sum((y_real - y_real.mean()) ** 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f4d1ba-702b-4e3f-aada-6e14668a4688",
   "metadata": {},
   "source": [
    "print(r_2_score(y_test, y_test_pred))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "395e4fb3-7c17-485f-81a6-2b92bcb21e4c",
   "metadata": {},
   "source": [
    "print(r_2_score(y_noise, y_pred))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2858c9a1-69fc-4f9a-8eba-9811baa0d04d",
   "metadata": {},
   "source": [
    "Now we compare to the LinearRegression of scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "615c345c-ab62-40de-ae46-e8c69cc6d482",
   "metadata": {},
   "source": [
    "one_feature_linear = LinearRegression()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c7f44e-c558-4cf4-b6f1-2c7f2be8bf0f",
   "metadata": {},
   "source": [
    "x_reshaped = x.reshape(-1, 1)\n",
    "y_resahped = y_noise.reshape(-1, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "923ba82b-7b75-4046-b3ff-1990b56cb9d1",
   "metadata": {},
   "source": [
    "one_feature_linear.fit(x_reshaped, y_resahped)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e6e9977-168f-4960-b341-169214690753",
   "metadata": {},
   "source": [
    "# check out the 'a' coefficient\n",
    "one_feature_linear.coef_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93b3a76e-cb6f-4595-a399-b21a0bf06406",
   "metadata": {},
   "source": [
    "# check out the interceptor\n",
    "one_feature_linear.intercept_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a6442c2-301f-4133-b7ea-b9f13f6dbdb8",
   "metadata": {},
   "source": [
    "# check out the score on test data\n",
    "x_test_reshape = x_test.reshape(-1, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8803414d-cd3f-4368-99dd-948df67cc435",
   "metadata": {},
   "source": [
    "model_pred = one_feature_linear.predict(x_test_reshape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3b7ed77-5bbb-4720-96f6-42d70c507dfc",
   "metadata": {},
   "source": [
    "plt.plot(x_test_reshape, model_pred, c='r', label='LinearModel prediction', linestyle='--')\n",
    "plt.plot(x_test, y_test_pred, label='My model prediciton')\n",
    "plt.xlabel('Input data')\n",
    "plt.ylabel('Output data')\n",
    "plt.title('Custom created model VS LinearModel')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f7a20e2b-49df-423c-88aa-eaef337ea7c0",
   "metadata": {},
   "source": [
    "Plotting the data we see perfect match. Now we will try **multifeature linear regression**. The equation is $$y = w_1x_1 + w_2x_2 + \\dots + w_nx_n + b$$ \n",
    "Where:\n",
    "\n",
    "- $x_1, x_2, \\dots, x_n$ are the input features.\n",
    "- $w_1, w_2, \\dots, w_n$​ are the coefficients (slopes) for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0ae22906-a613-4d82-9915-b66362f228e0",
   "metadata": {},
   "source": [
    "# defining the features\n",
    "def generate_features(number=1, random_range=(-5, 5), points=1000):\n",
    "    return np.array([np.linspace(np.random.randint(*random_range), np.random.randint(*random_range), points) for _ in\n",
    "                     range(number)])\n",
    "\n",
    "\n",
    "def generate_slopes(number=1, random_range=(-5, 5)):\n",
    "    return [np.random.randint(*random_range) for _ in range(number)]\n",
    "\n",
    "\n",
    "def calculate_real_output(features, slopes, interceptor):\n",
    "    # Initialize an array for the sum of features multiplied by their slopes\n",
    "    result_sum = np.zeros(features.shape[1])  # Shape matches the number of points in the features\n",
    "\n",
    "    # Multiply each feature by its corresponding slope and sum\n",
    "    for i in range(len(features)):\n",
    "        result_sum += features[i] * slopes[i]  # Correctly multiply and sum the features and slopes\n",
    "\n",
    "    # Generate random noise\n",
    "    eps = np.random.randn(len(result_sum))\n",
    "\n",
    "    # # Add the intercept term and noice\n",
    "    return result_sum + interceptor + eps"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82e87a75-2c8a-430b-94a4-5cbeb1a160af",
   "metadata": {},
   "source": [
    "features = generate_features(number=3)\n",
    "slopes = generate_slopes(number=len(features))\n",
    "interceptor = 2\n",
    "y_real = calculate_real_output(features, slopes, interceptor)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "308d24a1-2ce4-4ba8-b2db-2f5f38d2e9ca",
   "metadata": {},
   "source": [
    "for i in range(len(features)):\n",
    "    plt.scatter(features[i], y_pred, s=1)\n",
    "plt.title('Real output data')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Output')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e09222f0-c130-44de-a582-4ed064454ef5",
   "metadata": {},
   "source": [
    "class CustomLinearRegression:\n",
    "    def __init__(self):\n",
    "        self._coef = None  # Internal attribute to store the coefficients\n",
    "        self._intercept = None\n",
    "    \n",
    "    @property\n",
    "    def intercept_(self):\n",
    "        return self._intercept\n",
    "    \n",
    "    @intercept_.setter\n",
    "    def intercept_(self, value):\n",
    "        if value is not None:\n",
    "            self._intercept = value  # Update the internal attribute\n",
    "    \n",
    "    @property\n",
    "    def coef_(self):\n",
    "        \"\"\"Getter for coef_\"\"\"\n",
    "        return self._coef\n",
    "\n",
    "    @coef_.setter\n",
    "    def coef_(self, value):\n",
    "        \"\"\"Setter for coef_\"\"\"\n",
    "        if value is not None:\n",
    "            self._coef = value  # Update the internal attribute\n",
    "\n",
    "           \n",
    "    def fit(self, features, target, alpha=0.01, iterations=1000, random_state=None):\n",
    "        \"\"\"Perform fit with gradient descent.\"\"\"\n",
    "        # Set the random seed for reproducibility\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "        slopes = self._generate_slopes(len(features))\n",
    "        # interceptor = np.random.randint(-2, 2)\n",
    "        # set interceptor always to be 0\n",
    "        interceptor = 0\n",
    "\n",
    "        for i in range(iterations):\n",
    "            slopes, interceptor = self._gradient_descent(features, target, slopes, interceptor, alpha)\n",
    "\n",
    "        self.coef_ = slopes\n",
    "\n",
    "        return \"Model fit\"\n",
    "\n",
    "    def _parameter_gradient(self, features, target, slopes, interceptor):\n",
    "        \"\"\" using MSE \"\"\"\n",
    "        gradients = []\n",
    "        for i, feature in enumerate(features):\n",
    "            gradients.append(-2 / len(feature) * np.sum(\n",
    "                feature * (target - (self._linear_combination(features, slopes, interceptor)))))\n",
    "\n",
    "        interceptor_gradient = -2 / len(features[0]) * np.sum(\n",
    "            target - (self._linear_combination(features, slopes, interceptor)))\n",
    "\n",
    "        return gradients, interceptor_gradient\n",
    "\n",
    "    def _gradient_descent(self, features, target, slopes, interceptor, alpha):\n",
    "\n",
    "        gradients, interceptor_gradient = self._parameter_gradient(features, target, slopes, interceptor)\n",
    "\n",
    "        slopes_new = []\n",
    "        for i, slope in enumerate(slopes):\n",
    "            slopes_new.append(slopes[i] - alpha * gradients[i])\n",
    "\n",
    "        interceptor_new = interceptor - alpha * interceptor_gradient\n",
    "\n",
    "        return slopes_new, interceptor_new\n",
    "\n",
    "    def _generate_slopes(self, number, random_range=(-1, 1)):\n",
    "        # generates initial slopes and are in range (-1; 1)\n",
    "        return [np.random.randint(*random_range) for _ in range(number)]\n",
    "\n",
    "    def _linear_combination(self, features, slopes, interceptor):\n",
    "        # Initialize an array for the sum of features multiplied by their slopes\n",
    "        result_sum = np.zeros(features.shape[1])  # Shape matches the number of points in the features\n",
    "\n",
    "        # Multiply each feature by its corresponding slope and sum\n",
    "        for i in range(len(features)):\n",
    "            result_sum += features[i] * slopes[i]  # Correctly multiply and sum the features and slopes\n",
    "\n",
    "        # Add the intercept term\n",
    "        return result_sum + interceptor"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "29ec55e0-9054-4aa0-a898-e2fc0e7d76fe",
   "metadata": {},
   "source": [
    "custom_model = CustomLinearRegression()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9bd8b16b-6c6f-47f7-8770-4243cf7fdb9f",
   "metadata": {},
   "source": [
    "custom_model.fit(features, y_real, alpha=0.01, iterations=100000, random_state=12)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c0375d37-d6fd-423c-aa8e-c35060fbba93",
   "metadata": {},
   "source": [
    "slopes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1ed581f-bb9a-48e4-8f49-cac3fed7b472",
   "metadata": {},
   "source": [
    "interceptor"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6e8e203c-0a5f-49ad-a722-1eb264c114f9",
   "metadata": {},
   "source": [
    "# comparing to LinearRegression\n",
    "multi_model = LinearRegression()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b90273a8-e84b-427e-950e-7ceb9eca36e6",
   "metadata": {},
   "source": [
    "multi_model.fit(features.T, y_real)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3190b619-1d45-41d3-845c-e7f03ac6df72",
   "metadata": {},
   "source": [
    "multi_model.coef_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e3638763-5cb6-4d62-ae49-dd61cbd95166",
   "metadata": {},
   "source": [
    "multi_model.intercept_"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6a44871f-306c-48ae-8155-7b500dba0935",
   "metadata": {},
   "source": [
    "It is way off. Both models are missing the slopes. Will try to scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ccbf52e7-0088-4bee-b019-7add1d827754",
   "metadata": {},
   "source": [
    "scaler = MinMaxScaler()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "189976af-c68f-4bc7-bebc-f301d82343a7",
   "metadata": {},
   "source": [
    "features_scaled = scaler.fit_transform(features)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f38b63b-da9c-4443-ace6-618c88bb467f",
   "metadata": {},
   "source": [
    "multi_model.fit(features_scaled.T, y_real)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c4088f73-6fc5-4d0f-b4bf-a76c4db3f640",
   "metadata": {},
   "source": [
    "multi_model.coef_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fb16dc35-3ca6-437d-9908-77800c4245ee",
   "metadata": {},
   "source": [
    "multi_model.intercept_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0dbb647d-d1ce-4035-8487-97dbb9999547",
   "metadata": {},
   "source": [
    "custom_model.fit(features_scaled, y_real, alpha=0.01, iterations=10000)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b25c45-454c-4d41-9439-8d4f4a89b5a7",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
